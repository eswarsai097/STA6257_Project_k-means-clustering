---
title: "Sample Report - Data Science Capstone"
author: "Eswar Sai Prasad Burugupalley"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

### Introduction

Clustering is a technique for identifying groups of data (known as clusters) with similar properties. therefore you do not need to directly instruct your algorithm on how to group those observations because it does so on its own. As a result, observations (or data points) from the same group are more similar than observations from different groups. The goal is to get as many data points from the same group as feasible and as few data points from different groups as possible. 

One of the unsupervised machine learning algorithms is the k-means algorithm which is given a set of data points and clusters the data points into k clusters. This set of data points into cluster grouping process represents itself as the training step of a learning algorithm. The result will be a model which takes as input a data sample and returns the cluster to which the new data point belongs based on the training something that the model received. K-Means is just an algorithm of clustering. It uses distance between points as a similarity measure, founded on k means.

### Research Paper 1

citation : Ahmed, M., Seraj, R., & Islam, S. M. S. (2020). The k-means Algorithm: A Comprehensive Survey and Performance Evaluation. Electronics, 9(8), 1295. https://doi.org/10.3390/electronics9081295


The paper "Comprehensive Survey and Performance Evaluation of the k-Means Algorithms" presents the in-depth investigation of the k-means algorithm and its various variants which provide many insights about various limitations, recent developments, current experimental results. The author opens the study by noting the popularity in the research community and the importance of the k-means clustering algorithm as a potent data mining tool. It does, however, acknowledge the limitations of such an algorithm, pointing out issues with random initialisations of centroids, the requirement to know in advance the number of clusters present within a dataset, and also the inability of the algorithm to handle a wide variety of very different types of data.

It indicates the paper's value as a resource for students as well as professionals in machine learning and data mining. The general review of the k-means algorithm, including its limitations, current improvements and experimental prognosis in general, is essential for understanding more on the revolutionary application of the algorithm. The conclusion defines the study as a must-read for all who are interested in clustering methods and unsupervised learning techniques.

### Research Paper 2

Abbas, S. A., Aslam, A., Rehman, A. U., Abbasi, W. A., Arif, S., & Kazmi, S. Z. H. (2020). K-Means and K-Medoids: Cluster Analysis on Birth Data Collected in City Muzaffarabad, Kashmir. IEEE Access, 8, 151847-151855. https://doi.org/10.1109/ACCESS.2020.3014021

The authors highlight the important need to address pregnancy problems, which are a leading cause of death in low-income nations, as well as the large mortality rate differences between low- and high-income countries. This highlights the importance of region-specific research and solutions, as generic findings may not be universally applicable to varied populations. And, The study analyzes birth data using K-Means clustering techniques, with the purpose of giving useful information for medical decision-making and result prediction. The study's significance stems from its ability to help healthcare professionals make informed decisions and execute preventive interventions suited to the specific needs of the community in Muzaffarabad, Kashmir.

In the end, the study adds to the growing text of research focused at reducing gaps in healthcare and improving mother and child health outcomes in low-income communities. Using cluster analysis and machine learning approaches, the study suggests a possible avenue for establishing targeted interventions and individualized healthcare strategies to reduce the burden of pregnancy problems.

### Research Paper 3

M. Mardi and M. R. Keyvanpour, "GBKM: A New Genetic Based K-Means Clustering Algorithm," in 2021 7th International Conference on Web Research (ICWR), Tehran, Iran, 2021, pp. 222-226. DOI: 10.1109/ICWR51868.2021.9443113

Genetic-Based K-Means Clustering method discusses a method that aims to improve the performance of the traditional K-Means clustering approach. So, this presents a complete review of both the K-Means and Genetic algorithms, emphasizing their unique properties and applications. K-means method is explicitly defined as a centroid-based partitioning approach where the data is divided into k groupings. This involves initiation of cluster centroids, assigning of points to the nearest cluster, updating centroids of clusters, and iteration until resolution. This paper will also focus on the significance of the algorithm in data mining and use of distance functions as provided by Euclidean and Manhattan metrics. In this section, the performance evaluation of GBKM algorithm tested with three datasets is discussed as part of experimental results and compared to other existing clustering algorithms like hierarchical clustering algorithm, Density-Based spatial Clustering of Applications with Noise but mostly known as DBSCAN, K-Means. The results show that the GBKM algorithm can achieve faster results and higher clustering accuracy.

The paper is a good resource for understanding the GBKM algorithm and its potential applications in data clustering, revealing how genetic algorithms can be developed to deliver increased efficiency when compared to current clustering approaches.

### Research Paper 4

M. R. Fahlevi et al., "Determination of Rice Quality Using the K-Means Clustering Method," in 2020 2nd International Conference on Cybernetics and Intelligent System (ICORIS), Manado, Indonesia, 2020, pp. 1-6. DOI: 10.1109/ICORIS50180.2020.9320839

The research paper is about Determination of Rice Quality Applying the K-Means Clustering Method". analyzes the use of the K-Means Clustering algorithm to categorize rice based on quality. The study analyzed data from 206 rice brands, employing K-Means Clustering to create three clusters: very good quality, good quality, and low quality. Results indicated 49 brands as very good quality, 131 as good quality, and 26 as bad quality. The K-Means Clustering method, a fast and simple non-hierarchical approach, categorizes data based on equality among members. The method uses the Euclidean distance formula to compute the distance between the object center and each centroid, and then clusters the data for each cluster depending on its proximity to the shortest centroid distance. The strategy can help buyers make informed judgments and vendors choose the best pricing for their rice products. Overall, the research sheds light on how the K-Means Clustering approach can be utilized to classify rice depending on quality.

#### What is "method"?

This is an introduction to Kernel regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The GEE [@wang2014].

This is my work and I want to add more work...

### Related work

This section is going to cover the literature review...

## Methods

The common non-parametric regression model is
$Y_i = m(X_i) + \varepsilon_i$, where $Y_i$ can be defined as the sum of
the regression function value $m(x)$ for $X_i$. Here $m(x)$ is unknown
and $\varepsilon_i$ some errors. With the help of this definition, we
can create the estimation for local averaging i.e. $m(x)$ can be
estimated with the product of $Y_i$ average and $X_i$ is near to $x$. In
other words, this means that we are discovering the line through the
data points with the help of surrounding data points. The estimation
formula is printed below [@R-base]:

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$ $W_n(x)$ is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if $X_i$ is far from $x$.

Another equation:

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data and Visualization

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Statistical Modeling

```{r}

```

### Conclusion

## References
